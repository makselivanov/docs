# Ошибки при работе коннектора Spark

При работе со Spark в хранилище проекта создается скрытая папка `.spark/`, внутри которой находится служебная информация обо всех коннекторах Spark, доступных в проекте. Чтобы увидеть скрытые файлы и папки, на верхней панели интерфейса {{ jlab }}Lab нажмите **View** ⟶ **Show Hidden Files**.

Spark-сессия создается до запуска первой ячейки ноутбука и доступна через переменную `spark`. Если при создании сессии произошла ошибка, переменная `spark` не будет доступна, а отчет об ошибке появится в файле вида `.spark/connector/<идентификатор_коннектора>/session_creation_err_<время_ошибки>.txt`. Приложите этот файл при обращении [в поддержку]({{ link-console-support }}).

## Ошибка записи данных в S3 {#s3-load-data}

Если при записи данных в S3 возникла ошибка `Could not find any valid local directory for s3ablock-0001`, то в настройках коннектора Spark в блоке **{{ ui-key.yc-ui-datasphere.spark-connector.spark-settings }}** добавьте один из параметров:

Параметр | Описание
---|---
`spark.hadoop.fs.s3a.fast.upload.buffer` = `bytebuffer` | Быстрая загрузка файлов с помощью RAM. Размер файла не должен превышать количество доступной оперативной памяти
`spark.hadoop.fs.s3a.buffer.dir` = `/tmp` | Обычная загрузка на диск
